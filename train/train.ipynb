{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30_32\n",
      "Train batch after SMOTE: torch.Size([2048, 1, 32, 9]) torch.Size([2048])\n",
      "Validation batch: torch.Size([2048, 1, 32, 9]) torch.Size([2048])\n",
      "Test batch: torch.Size([2048, 1, 32, 9]) torch.Size([2048])\n",
      "Epoch [1/2], Step [4500/8577], Loss: 0.0031\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 166\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m    165\u001b[0m     model_fp\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m--> 166\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, (images, labels) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader_resampled):\n\u001b[1;32m    167\u001b[0m         images \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    168\u001b[0m         labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/miniconda3/envs/human_action/lib/python3.8/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/human_action/lib/python3.8/site-packages/torch/utils/data/dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    676\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 677\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    678\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    679\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniconda3/envs/human_action/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/envs/human_action/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[3], line 95\u001b[0m, in \u001b[0;36mCustomDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     93\u001b[0m label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels[idx]\n\u001b[1;32m     94\u001b[0m sample \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(sample, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# Thêm chiều mới tại vị trí index 0\u001b[39;00m\n\u001b[0;32m---> 95\u001b[0m label \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlong\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sample, label\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import shutil\n",
    "# Định nghĩa CustomDataset\n",
    "from utils import *\n",
    "import gc\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, MaxAbsScaler, RobustScaler\n",
    "from sklearn.utils import resample\n",
    "\n",
    "def unique_rows(matrix):\n",
    "    seen = set()\n",
    "    unique_matrix = []\n",
    "    for row in matrix:\n",
    "        row_tuple = tuple(row)\n",
    "        if row_tuple not in seen:\n",
    "            seen.add(row_tuple)\n",
    "            unique_matrix.append(row)\n",
    "    return np.vstack(unique_matrix)\n",
    "\n",
    "def unique_data(data_t, labels_t):\n",
    "    data_flat = data_t.reshape(data_t.shape[0], -1)\n",
    "    datala_t = np.hstack((data_flat, labels_t.reshape(-1, 1)))\n",
    "    datala_t = unique_rows(datala_t)\n",
    "    data = datala_t[:, :-1].reshape(-1, data_t.shape[1], 9).astype(np.float32)\n",
    "    labels = datala_t[:, -1].astype(int)\n",
    "    return data, labels\n",
    "\n",
    "batch_size = 2048\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "for time_window in [30]:\n",
    "    for h_windows in [32, 16, 8]:\n",
    "        print(f'{str(time_window)}_{str(h_windows)}')\n",
    "        with h5py.File('/mnt/d/dataset_pre/CICDDoS2017/'+str(time_window)+str(h_windows)+'_data_fix.h5', 'r') as hf:\n",
    "            data_cic = hf['data'][:]\n",
    "        with h5py.File('/mnt/d/dataset_pre/CICDDoS2017/'+str(time_window)+str(h_windows)+'_labels_fix.h5', 'r') as hf:\n",
    "            labels_cic = hf['labels'][:]\n",
    "        data_cic, labels_cic = unique_data(data_cic, labels_cic)\n",
    "        with h5py.File('/mnt/e/botiot/'+str(time_window)+str(h_windows)+'_data.h5', 'r') as hf:\n",
    "            data = hf['data'][:]\n",
    "        with h5py.File('/mnt/e/botiot/'+str(time_window)+str(h_windows)+'_labels.h5', 'r') as hf:\n",
    "            labels_ = hf['labels'][:]\n",
    "            labels_[np.where(labels_ == 2)] = 1\n",
    "        n_samples, height, width = data.shape\n",
    "        train_data_reshaped = data.reshape(n_samples, height * width)\n",
    "        # Áp dụng SMOTE\n",
    "        sm = SMOTE(random_state=42)\n",
    "        train_shape = train_data_reshaped.shape[0]\n",
    "        train_data_res, train_labels_res = sm.fit_resample(train_data_reshaped, labels_)\n",
    "        train_data_res1, train_labels_res1 = sm.fit_resample(train_data_reshaped, labels_)\n",
    "        train_data_res = np.vstack([train_data_res,train_data_res1])\n",
    "        train_labels_res = np.hstack([train_labels_res,train_labels_res1])\n",
    "        train_data_res1, train_labels_res1 = sm.fit_resample(train_data_reshaped, labels_)\n",
    "        train_data_res = np.vstack([train_data_res,train_data_res1])\n",
    "        train_labels_res = np.hstack([train_labels_res,train_labels_res1])\n",
    "        del train_data_res1\n",
    "        del train_labels_res1\n",
    "        gc.collect()\n",
    "        data = train_data_res\n",
    "        labels_ = train_labels_res\n",
    "        del train_data_res\n",
    "        del train_labels_res\n",
    "        gc.collect() \n",
    "        data.reshape(data.shape)\n",
    "        data = data.reshape(-1,h_windows,9)\n",
    "        data = np.concatenate([data,data_cic])\n",
    "        labels_ = np.concatenate([labels_,labels_cic])\n",
    "        del data_cic\n",
    "        del labels_cic\n",
    "        gc.collect()\n",
    "        data_reshaped = data.reshape(-1, data.shape[-1])\n",
    "        scaler = MinMaxScaler()\n",
    "        normalized_data_reshaped = scaler.fit_transform(data_reshaped)\n",
    "        data = normalized_data_reshaped.reshape(data.shape)\n",
    "        class CustomDataset(Dataset):\n",
    "            def __init__(self, data, labels):\n",
    "                self.data = data\n",
    "                self.labels = labels\n",
    "\n",
    "            def __len__(self):\n",
    "                return len(self.data)\n",
    "\n",
    "            def __getitem__(self, idx):\n",
    "                sample = self.data[idx]\n",
    "                label = self.labels[idx]\n",
    "                sample = torch.tensor(sample, dtype=torch.float32).unsqueeze(0)  # Thêm chiều mới tại vị trí index 0\n",
    "                label = torch.tensor(label, dtype=torch.long)\n",
    "                return sample, label\n",
    "        dataset = CustomDataset(data, labels_)\n",
    "        train_idx, temp_idx, train_labels, temp_labels = train_test_split(\n",
    "            np.arange(len(data)), labels_, test_size=0.4, stratify=labels_, random_state=42)\n",
    "        valid_idx, test_idx, valid_labels, test_labels = train_test_split(\n",
    "            temp_idx, temp_labels, test_size=0.5, stratify=temp_labels, random_state=42)\n",
    "        train_data = data[train_idx]\n",
    "        train_labels = labels_[train_idx]\n",
    "        train_dataset_resampled = CustomDataset(train_data, train_labels)\n",
    "\n",
    "        valid_dataset = Subset(dataset, valid_idx)\n",
    "        test_dataset = Subset(dataset, test_idx)\n",
    "        train_loader_resampled = DataLoader(train_dataset_resampled, batch_size=batch_size, shuffle=True)\n",
    "        valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "        for batch_data, batch_labels in train_loader_resampled:\n",
    "            print('Train batch after SMOTE:', batch_data.shape, batch_labels.shape)\n",
    "            break  # chỉ in ra một batch để kiểm tra\n",
    "\n",
    "        for batch_data, batch_labels in valid_loader:\n",
    "            print('Validation batch:', batch_data.shape, batch_labels.shape)\n",
    "            break \n",
    "\n",
    "        for batch_data, batch_labels in test_loader:\n",
    "            print('Test batch:', batch_data.shape, batch_labels.shape)\n",
    "            break  \n",
    "        for quant in ['FP', 'TNN', 'TBN', 'BNN']:\n",
    "            if quant == 'FP':\n",
    "                class Q_CAD(nn.Module):\n",
    "                    def __init__(self):\n",
    "                        super(Q_CAD, self).__init__()\n",
    "                        self.conv1 = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=(3,3), padding=1)\n",
    "                        self.conv2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3,3), padding=1)\n",
    "                        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "                        self.fc1 = nn.Linear(in_features=64 * int(h_windows/4) * 2, out_features=128)\n",
    "                        self.fc2 = nn.Linear(in_features=128, out_features=2) \n",
    "                        \n",
    "                    def forward(self, x):\n",
    "                        x = F.relu(self.pool(self.conv1(x)))\n",
    "                        x = F.relu(self.pool(self.conv2(x)))\n",
    "                        x = x.view(x.size(0), -1)\n",
    "                        x = F.relu(self.fc1(x))\n",
    "                        x = self.fc2(x)\n",
    "                        return x\n",
    "            else:\n",
    "                class Q_CAD(nn.Module):\n",
    "                    def __init__(self):\n",
    "                        super(Q_CAD, self).__init__()\n",
    "                        self.conv1 = QConv2d(in_channels=1, out_channels=64, kernel_size=(3, 3), padding=1, quant=quant)\n",
    "                        self.conv2 = QConv2d(in_channels=64, out_channels=64, kernel_size=(3, 3), padding=1, quant=quant)\n",
    "                        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "                        self.fc1 = QLinear(in_features=64 * int(h_windows/4) * 2, out_features=128, quant=quant)\n",
    "                        self.fc2 = QLinear(in_features=128, out_features=2, quant=quant)\n",
    "                        \n",
    "                    def forward(self, x):\n",
    "                        x = self.pool(self.conv1(x))\n",
    "                        x = self.pool(self.conv2(x))\n",
    "                        x = x.view(x.size(0), -1)\n",
    "                        x = self.fc1(x)\n",
    "                        x = self.fc2(x)\n",
    "                        return x\n",
    "\n",
    "            model_fp = Q_CAD().to(device)\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            optimizer = optim.Adam(model_fp.parameters(), lr=0.001)\n",
    "            best_accuracy = 0.0\n",
    "            best_epoch = 0\n",
    "            num_epochs = 2\n",
    "            for epoch in range(num_epochs):\n",
    "                model_fp.train()\n",
    "                for i, (images, labels) in enumerate(train_loader_resampled):\n",
    "                    images = images.to(device)\n",
    "                    labels = labels.to(device)\n",
    "                    \n",
    "                    outputs = model_fp(images)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    \n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    \n",
    "                    if (i+1) % 100 == 0:\n",
    "                        print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader_resampled)}], Loss: {loss.item():.4f}', end='\\r')\n",
    "                \n",
    "                model_fp.eval()\n",
    "                with torch.no_grad():\n",
    "                    correct = 0\n",
    "                    total = 0\n",
    "                    all_labels = []\n",
    "                    all_predictions = []\n",
    "                    for images, labels in valid_loader:\n",
    "                        images = images.to(device)\n",
    "                        labels = labels.to(device)\n",
    "                        \n",
    "                        outputs = model_fp(images)\n",
    "                        _, predicted = torch.max(outputs.data, 1)\n",
    "                        total += labels.size(0)\n",
    "                        correct += (predicted == labels).sum().item()\n",
    "                        all_labels.extend(labels.cpu().numpy())\n",
    "                        all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "                    accuracy = 100 * correct / total\n",
    "                    f1 = f1_score(all_labels, all_predictions, average='weighted')\n",
    "                    precision = precision_score(all_labels, all_predictions, average='weighted')\n",
    "                    recall = recall_score(all_labels, all_predictions, average='weighted')\n",
    "                    cm = confusion_matrix(all_labels, all_predictions)\n",
    "                    tn, fp, fn, tp = cm.ravel()\n",
    "                    fpr = fp / (fp + tn)\n",
    "                    ppv = precision\n",
    "                    tpr = recall\n",
    "\n",
    "                    print(f'Epoch [{epoch + 1}/{num_epochs}], Validation Accuracy: {accuracy:.2f}%, F1: {f1:.2f}, PPV: {ppv:.2f}, TPR: {tpr:.2f}, FPR: {fpr:.4f}')\n",
    "\n",
    "                    # Lưu lại mô hình nếu độ chính xác tốt hơn\n",
    "                    if accuracy > best_accuracy:\n",
    "                        best_accuracy = accuracy\n",
    "                        best_epoch = epoch + 1\n",
    "                        torch.save(model_fp.state_dict(), 'best_model.pth')\n",
    "\n",
    "            print(f'Best Validation Accuracy: {best_accuracy:.2f}% at epoch {best_epoch}')\n",
    "\n",
    "            # Đánh giá cuối cùng trên tập test\n",
    "            model_fp.load_state_dict(torch.load('best_model.pth'))\n",
    "            model_fp.eval()\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            all_labels = []\n",
    "            all_predictions = []\n",
    "            with torch.no_grad():\n",
    "                for images, labels in test_loader:\n",
    "                    images = images.to(device)\n",
    "                    labels = labels.to(device)\n",
    "                    \n",
    "                    outputs = model_fp(images)\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    total += labels.size(0)\n",
    "                    correct += (predicted == labels).sum().item()\n",
    "                    all_labels.extend(labels.cpu().numpy())\n",
    "                    all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "            test_accuracy = 100 * correct / total\n",
    "            f1 = f1_score(all_labels, all_predictions, average='weighted')\n",
    "            precision = precision_score(all_labels, all_predictions, average='weighted')\n",
    "            recall = recall_score(all_labels, all_predictions, average='weighted')\n",
    "            cm = confusion_matrix(all_labels, all_predictions)\n",
    "            tn, fp, fn, tp = cm.ravel()\n",
    "            fpr = fp / (fp + tn)\n",
    "            ppv = precision\n",
    "            tpr = recall\n",
    "\n",
    "            print(f'Test Accuracy: {test_accuracy:.2f}%, F1: {f1:.2f}, PPV: {ppv:.2f}, TPR: {tpr:.2f}, FPR: {fpr:.4f}')\n",
    "            shutil.copy('best_model.pth', f'model_save/{quant}{str(time_window)}{str(h_windows)}.pth')\n",
    "\n",
    "            file_path = '/home/usami/TBN64/train/model_acc.txt'\n",
    "            new_line = f'{quant}{str(time_window)}{str(h_windows)}: {test_accuracy:.2f}%, F1: {f1:.2f}, PPV: {ppv:.2f}, TPR: {tpr:.2f}, FPR: {fpr:.4f}\\n'\n",
    "            with open(file_path, 'a') as file:\n",
    "                file.write(new_line)\n",
    "        gc.collect()\n",
    "        with open(file_path, 'a') as file:\n",
    "            file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[3.5294e-01, 8.4270e-04, 1.0000e+00, 1.0720e-01, 5.7831e-05,\n",
       "          2.1927e-03, 4.3373e-05, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [3.5294e-01, 8.4270e-04, 1.0000e+00, 1.0720e-01, 5.7831e-05,\n",
       "          3.0175e-04, 4.3373e-05, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]]], device='cuda:0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "human_action",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
